{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f566e09",
   "metadata": {},
   "source": [
    "# Supervised Learning - Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad75ccd",
   "metadata": {},
   "source": [
    "In this Project, we are going to perform a full unsupervised learning machine learning project on a \"Wholesale Data\" dataset. The dataset refers to clients of a wholesale distributor. It includes the annual spending in monetary units (m.u.) on diverse product categories\n",
    "\n",
    "[Kaggle Link](https://www.kaggle.com/datasets/binovi/wholesale-customers-data-set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e57f31",
   "metadata": {},
   "source": [
    "# Part I : EDA - Exploratory Data Analysis & Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c827a5",
   "metadata": {},
   "source": [
    "The given dataset seems to be a grocery sales dataset containing information about various products sold by a grocery store. To perform an exploratory data analysis (EDA) on this dataset, we can perform the following tasks:\n",
    "\n",
    "- Data Import: Import the dataset into a statistical software tool such as Python or R.\n",
    "- Data Cleaning: Check the dataset for any missing or incorrect data and clean the dataset accordingly. This may involve removing or imputing missing data or correcting any obvious errors.\n",
    "Data Description: Generate summary statistics such as mean, median, and standard deviation for each column of the dataset. This will help in understanding the distribution of data in each column.\n",
    "- Data Visualization: Create various visualizations such as histograms, box plots, scatter plots, and heatmaps to understand the relationships and trends between the different variables in the dataset. For example, we can create a scatter plot between the \"Fresh\" and \"Milk\" variables to see if there is any correlation between them.\n",
    "- Outlier Detection: Check for any outliers in the dataset and determine whether they are valid or erroneous data points.\n",
    "- Correlation Analysis: Calculate the correlation between different variables in the dataset to determine which variables are highly correlated and which ones are not. For example, we can calculate the correlation between \"Grocery\" and \"Detergents_Paper\" to see if there is any relationship between these two variables.\n",
    "- Data Transformation: If necessary, transform the data by standardizing or normalizing the variables to make them comparable across different scales.\n",
    "- Feature Selection: Identify the most important features or variables that contribute the most to the overall variance in the dataset. This can be done using various feature selection techniques such as principal component analysis (PCA) or random forest regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bfb7c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports - Pandas, data analysis libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87e57560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel</th>\n",
       "      <th>Region</th>\n",
       "      <th>Fresh</th>\n",
       "      <th>Milk</th>\n",
       "      <th>Grocery</th>\n",
       "      <th>Frozen</th>\n",
       "      <th>Detergents_Paper</th>\n",
       "      <th>Delicassen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>12669</td>\n",
       "      <td>9656</td>\n",
       "      <td>7561</td>\n",
       "      <td>214</td>\n",
       "      <td>2674</td>\n",
       "      <td>1338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7057</td>\n",
       "      <td>9810</td>\n",
       "      <td>9568</td>\n",
       "      <td>1762</td>\n",
       "      <td>3293</td>\n",
       "      <td>1776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6353</td>\n",
       "      <td>8808</td>\n",
       "      <td>7684</td>\n",
       "      <td>2405</td>\n",
       "      <td>3516</td>\n",
       "      <td>7844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>13265</td>\n",
       "      <td>1196</td>\n",
       "      <td>4221</td>\n",
       "      <td>6404</td>\n",
       "      <td>507</td>\n",
       "      <td>1788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>22615</td>\n",
       "      <td>5410</td>\n",
       "      <td>7198</td>\n",
       "      <td>3915</td>\n",
       "      <td>1777</td>\n",
       "      <td>5185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Channel  Region  Fresh  Milk  Grocery  Frozen  Detergents_Paper  Delicassen\n",
       "0        2       3  12669  9656     7561     214              2674        1338\n",
       "1        2       3   7057  9810     9568    1762              3293        1776\n",
       "2        2       3   6353  8808     7684    2405              3516        7844\n",
       "3        1       3  13265  1196     4221    6404               507        1788\n",
       "4        2       3  22615  5410     7198    3915              1777        5185"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import wholesale_data\n",
    "\n",
    "data = pd.read_csv('wholesale_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b62779",
   "metadata": {},
   "source": [
    "Step 1: Basic data exploration e.g. shape, nulls, data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2adc929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(440, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape\n",
    "# 440 rows of 8 columns / features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "404784db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 440 entries, 0 to 439\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype\n",
      "---  ------            --------------  -----\n",
      " 0   Channel           440 non-null    int64\n",
      " 1   Region            440 non-null    int64\n",
      " 2   Fresh             440 non-null    int64\n",
      " 3   Milk              440 non-null    int64\n",
      " 4   Grocery           440 non-null    int64\n",
      " 5   Frozen            440 non-null    int64\n",
      " 6   Detergents_Paper  440 non-null    int64\n",
      " 7   Delicassen        440 non-null    int64\n",
      "dtypes: int64(8)\n",
      "memory usage: 27.6 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()\n",
    "# all integers and all non null, perhaps some outliers or 0 values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d33439c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel</th>\n",
       "      <th>Region</th>\n",
       "      <th>Fresh</th>\n",
       "      <th>Milk</th>\n",
       "      <th>Grocery</th>\n",
       "      <th>Frozen</th>\n",
       "      <th>Detergents_Paper</th>\n",
       "      <th>Delicassen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>440.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>440.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.322727</td>\n",
       "      <td>2.543182</td>\n",
       "      <td>12000.297727</td>\n",
       "      <td>5796.265909</td>\n",
       "      <td>7951.277273</td>\n",
       "      <td>3071.931818</td>\n",
       "      <td>2881.493182</td>\n",
       "      <td>1524.870455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.468052</td>\n",
       "      <td>0.774272</td>\n",
       "      <td>12647.328865</td>\n",
       "      <td>7380.377175</td>\n",
       "      <td>9503.162829</td>\n",
       "      <td>4854.673333</td>\n",
       "      <td>4767.854448</td>\n",
       "      <td>2820.105937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3127.750000</td>\n",
       "      <td>1533.000000</td>\n",
       "      <td>2153.000000</td>\n",
       "      <td>742.250000</td>\n",
       "      <td>256.750000</td>\n",
       "      <td>408.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8504.000000</td>\n",
       "      <td>3627.000000</td>\n",
       "      <td>4755.500000</td>\n",
       "      <td>1526.000000</td>\n",
       "      <td>816.500000</td>\n",
       "      <td>965.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>16933.750000</td>\n",
       "      <td>7190.250000</td>\n",
       "      <td>10655.750000</td>\n",
       "      <td>3554.250000</td>\n",
       "      <td>3922.000000</td>\n",
       "      <td>1820.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>112151.000000</td>\n",
       "      <td>73498.000000</td>\n",
       "      <td>92780.000000</td>\n",
       "      <td>60869.000000</td>\n",
       "      <td>40827.000000</td>\n",
       "      <td>47943.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Channel      Region          Fresh          Milk       Grocery  \\\n",
       "count  440.000000  440.000000     440.000000    440.000000    440.000000   \n",
       "mean     1.322727    2.543182   12000.297727   5796.265909   7951.277273   \n",
       "std      0.468052    0.774272   12647.328865   7380.377175   9503.162829   \n",
       "min      1.000000    1.000000       3.000000     55.000000      3.000000   \n",
       "25%      1.000000    2.000000    3127.750000   1533.000000   2153.000000   \n",
       "50%      1.000000    3.000000    8504.000000   3627.000000   4755.500000   \n",
       "75%      2.000000    3.000000   16933.750000   7190.250000  10655.750000   \n",
       "max      2.000000    3.000000  112151.000000  73498.000000  92780.000000   \n",
       "\n",
       "             Frozen  Detergents_Paper    Delicassen  \n",
       "count    440.000000        440.000000    440.000000  \n",
       "mean    3071.931818       2881.493182   1524.870455  \n",
       "std     4854.673333       4767.854448   2820.105937  \n",
       "min       25.000000          3.000000      3.000000  \n",
       "25%      742.250000        256.750000    408.250000  \n",
       "50%     1526.000000        816.500000    965.500000  \n",
       "75%     3554.250000       3922.000000   1820.250000  \n",
       "max    60869.000000      40827.000000  47943.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e39b20",
   "metadata": {},
   "source": [
    "Initial impressions:\n",
    "- Numerically, Channel and Region are completely distinct from Fresh, Milk etc the other later columns. If this is sales / wholesale data then this makes sense as channel and Region are probably encoded values that represent the names of different regions e.g. North, South, West... and Channels e.g. Online, in-store, retail partner etc.\n",
    "- To evidence this, we can look at number of unique values for each column, it's very likely there's only around a maximum of 5-10 channels (online/instore/retail/events...????) or 10-20 regions (north/south/east/west/central/mountain/coast...????) but the number of sales of product categories would be much much higher than this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95af84a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel\n",
      "1    298\n",
      "2    142\n",
      "Name: count, dtype: int64\n",
      "Region\n",
      "3    316\n",
      "1     77\n",
      "2     47\n",
      "Name: count, dtype: int64\n",
      "Fresh\n",
      "9670     2\n",
      "3        2\n",
      "18044    2\n",
      "8040     2\n",
      "514      2\n",
      "        ..\n",
      "18827    1\n",
      "10405    1\n",
      "37036    1\n",
      "30379    1\n",
      "2787     1\n",
      "Name: count, Length: 433, dtype: int64\n",
      "Grocery\n",
      "1664    2\n",
      "2062    2\n",
      "683     2\n",
      "3600    2\n",
      "6536    2\n",
      "       ..\n",
      "7305    1\n",
      "3343    1\n",
      "5034    1\n",
      "8282    1\n",
      "2510    1\n",
      "Name: count, Length: 430, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['Channel'].value_counts()) # only two channels\n",
    "\n",
    "print(data['Region'].value_counts()) # only three regions\n",
    "\n",
    "print(data['Fresh'].value_counts()) # 433 different unique values for Fresh category\n",
    "\n",
    "print(data['Grocery'].value_counts()) # 430 different unique values for Grocery category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902ae81a",
   "metadata": {},
   "source": [
    "Next Steps:\n",
    "- I'm fully convinced Region and Channel are label encoded variables whereas the other categories are the actual sales data\n",
    "- for K Means Clustering I would therefore lean toward three (for region) or two (channel) means for modelling as a first run, before anything else is learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd6c6f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd472b2a",
   "metadata": {},
   "source": [
    "# Part II - KMeans Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54982ce3",
   "metadata": {},
   "source": [
    "The objective of the analysis is to group similar products together into clusters based on their attributes such as fresh, milk, grocery, frozen, detergents_paper, and delicatessen. To perform the k-means clustering analysis, you will need to pre-process the dataset, determine the optimal number of clusters, initialize the centroids, assign data points to clusters, update the centroids, and repeat until convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe55289",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44f48cda",
   "metadata": {},
   "source": [
    "# Part III - Hierarchical Clustering "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ba2210",
   "metadata": {},
   "source": [
    "Hierarchical clustering is a popular unsupervised machine learning algorithm that is used to identify patterns and group similar data points together in a hierarchy. The algorithm works by iteratively merging or splitting clusters based on a similarity measure until a dendrogram is formed.\n",
    "\n",
    "To perform hierarchical clustering analysis, you will need to pre-process the dataset, determine the optimal number of clusters using techniques such as dendrogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2a4ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd516495",
   "metadata": {},
   "source": [
    "# Part IV - PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7cf638",
   "metadata": {},
   "source": [
    "In this section you are going to perform principal component analysis (PCA) to draw conclusions about the underlying structure of the wholesale customer data. Since using PCA on a dataset calculates the dimensions which best maximize variance, we will find which compound combinations of features best describe customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfd148a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "193765ae",
   "metadata": {},
   "source": [
    "# Part V - Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc26f00",
   "metadata": {},
   "source": [
    "From the model you developed and the exploratory data analysis (EDA) conducted, generate four bullet points as your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb81361",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
